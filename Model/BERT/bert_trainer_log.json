[
  {
    "loss": 1.6955,
    "grad_norm": 9.003586769104004,
    "learning_rate": 4.924002436795614e-05,
    "epoch": 0.07614986293024673,
    "step": 500
  },
  {
    "loss": 1.2705,
    "grad_norm": 14.938265800476074,
    "learning_rate": 4.8478525738653674e-05,
    "epoch": 0.15229972586049345,
    "step": 1000
  },
  {
    "loss": 1.1749,
    "grad_norm": 11.087992668151855,
    "learning_rate": 4.7717027109351206e-05,
    "epoch": 0.22844958879074018,
    "step": 1500
  },
  {
    "loss": 1.1178,
    "grad_norm": 6.165165901184082,
    "learning_rate": 4.695552848004874e-05,
    "epoch": 0.3045994517209869,
    "step": 2000
  },
  {
    "loss": 1.0749,
    "grad_norm": 5.024112701416016,
    "learning_rate": 4.6194029850746277e-05,
    "epoch": 0.38074931465123363,
    "step": 2500
  },
  {
    "loss": 1.041,
    "grad_norm": 7.233465194702148,
    "learning_rate": 4.54325312214438e-05,
    "epoch": 0.45689917758148035,
    "step": 3000
  },
  {
    "loss": 1.027,
    "grad_norm": 6.802304744720459,
    "learning_rate": 4.467103259214134e-05,
    "epoch": 0.5330490405117271,
    "step": 3500
  },
  {
    "loss": 1.0384,
    "grad_norm": 12.527167320251465,
    "learning_rate": 4.3909533962838865e-05,
    "epoch": 0.6091989034419738,
    "step": 4000
  },
  {
    "loss": 0.9969,
    "grad_norm": 6.58427095413208,
    "learning_rate": 4.3148035333536404e-05,
    "epoch": 0.6853487663722205,
    "step": 4500
  },
  {
    "loss": 0.994,
    "grad_norm": 5.006692409515381,
    "learning_rate": 4.2386536704233936e-05,
    "epoch": 0.7614986293024673,
    "step": 5000
  },
  {
    "loss": 0.9875,
    "grad_norm": 6.615036964416504,
    "learning_rate": 4.162503807493147e-05,
    "epoch": 0.837648492232714,
    "step": 5500
  },
  {
    "loss": 0.9458,
    "grad_norm": 6.86461067199707,
    "learning_rate": 4.0863539445629e-05,
    "epoch": 0.9137983551629607,
    "step": 6000
  },
  {
    "loss": 0.9646,
    "grad_norm": 5.611684799194336,
    "learning_rate": 4.010204081632653e-05,
    "epoch": 0.9899482180932074,
    "step": 6500
  },
  {
    "eval_loss": 0.9513958692550659,
    "eval_accuracy": 0.6692940370116518,
    "eval_runtime": 195.55,
    "eval_samples_per_second": 134.298,
    "eval_steps_per_second": 8.397,
    "epoch": 1.0,
    "step": 6566
  },
  {
    "loss": 0.8337,
    "grad_norm": 5.37516450881958,
    "learning_rate": 3.9340542187024064e-05,
    "epoch": 1.0660980810234542,
    "step": 7000
  },
  {
    "loss": 0.8199,
    "grad_norm": 20.277196884155273,
    "learning_rate": 3.85790435577216e-05,
    "epoch": 1.1422479439537008,
    "step": 7500
  },
  {
    "loss": 0.8261,
    "grad_norm": 8.826187133789062,
    "learning_rate": 3.781754492841913e-05,
    "epoch": 1.2183978068839476,
    "step": 8000
  },
  {
    "loss": 0.8273,
    "grad_norm": 6.078756332397461,
    "learning_rate": 3.7056046299116666e-05,
    "epoch": 1.2945476698141944,
    "step": 8500
  },
  {
    "loss": 0.8324,
    "grad_norm": 6.844700813293457,
    "learning_rate": 3.629454766981419e-05,
    "epoch": 1.370697532744441,
    "step": 9000
  },
  {
    "loss": 0.8532,
    "grad_norm": 6.8969316482543945,
    "learning_rate": 3.553304904051173e-05,
    "epoch": 1.4468473956746877,
    "step": 9500
  },
  {
    "loss": 0.8299,
    "grad_norm": 9.215421676635742,
    "learning_rate": 3.477155041120926e-05,
    "epoch": 1.5229972586049345,
    "step": 10000
  },
  {
    "loss": 0.8235,
    "grad_norm": 7.592181205749512,
    "learning_rate": 3.4010051781906794e-05,
    "epoch": 1.5991471215351813,
    "step": 10500
  },
  {
    "loss": 0.8322,
    "grad_norm": 5.1753129959106445,
    "learning_rate": 3.3248553152604326e-05,
    "epoch": 1.675296984465428,
    "step": 11000
  },
  {
    "loss": 0.8226,
    "grad_norm": 6.599730968475342,
    "learning_rate": 3.248705452330186e-05,
    "epoch": 1.7514468473956746,
    "step": 11500
  },
  {
    "loss": 0.8278,
    "grad_norm": 7.891322612762451,
    "learning_rate": 3.172555589399939e-05,
    "epoch": 1.8275967103259214,
    "step": 12000
  },
  {
    "loss": 0.8002,
    "grad_norm": 8.812845230102539,
    "learning_rate": 3.096405726469693e-05,
    "epoch": 1.9037465732561683,
    "step": 12500
  },
  {
    "loss": 0.8242,
    "grad_norm": 8.321246147155762,
    "learning_rate": 3.0202558635394457e-05,
    "epoch": 1.9798964361864149,
    "step": 13000
  },
  {
    "eval_loss": 0.9262405633926392,
    "eval_accuracy": 0.6776330820196481,
    "eval_runtime": 195.7779,
    "eval_samples_per_second": 134.142,
    "eval_steps_per_second": 8.387,
    "epoch": 2.0,
    "step": 13132
  },
  {
    "loss": 0.6858,
    "grad_norm": 9.46497631072998,
    "learning_rate": 2.9441060006091992e-05,
    "epoch": 2.0560462991166615,
    "step": 13500
  },
  {
    "loss": 0.6388,
    "grad_norm": 7.5574212074279785,
    "learning_rate": 2.867956137678952e-05,
    "epoch": 2.1321961620469083,
    "step": 14000
  },
  {
    "loss": 0.6337,
    "grad_norm": 7.749458312988281,
    "learning_rate": 2.7918062747487056e-05,
    "epoch": 2.208346024977155,
    "step": 14500
  },
  {
    "loss": 0.6426,
    "grad_norm": 5.044248104095459,
    "learning_rate": 2.715656411818459e-05,
    "epoch": 2.2844958879074015,
    "step": 15000
  },
  {
    "loss": 0.6345,
    "grad_norm": 8.703973770141602,
    "learning_rate": 2.639506548888212e-05,
    "epoch": 2.3606457508376484,
    "step": 15500
  },
  {
    "loss": 0.6418,
    "grad_norm": 8.794050216674805,
    "learning_rate": 2.5633566859579655e-05,
    "epoch": 2.436795613767895,
    "step": 16000
  },
  {
    "loss": 0.6595,
    "grad_norm": 8.722947120666504,
    "learning_rate": 2.4872068230277187e-05,
    "epoch": 2.512945476698142,
    "step": 16500
  },
  {
    "loss": 0.6454,
    "grad_norm": 7.637242794036865,
    "learning_rate": 2.411056960097472e-05,
    "epoch": 2.589095339628389,
    "step": 17000
  },
  {
    "loss": 0.6584,
    "grad_norm": 10.213467597961426,
    "learning_rate": 2.334907097167225e-05,
    "epoch": 2.6652452025586353,
    "step": 17500
  },
  {
    "loss": 0.6551,
    "grad_norm": 8.705408096313477,
    "learning_rate": 2.2587572342369783e-05,
    "epoch": 2.741395065488882,
    "step": 18000
  },
  {
    "loss": 0.6624,
    "grad_norm": 8.906580924987793,
    "learning_rate": 2.1826073713067318e-05,
    "epoch": 2.817544928419129,
    "step": 18500
  },
  {
    "loss": 0.6359,
    "grad_norm": 11.40530776977539,
    "learning_rate": 2.106457508376485e-05,
    "epoch": 2.8936947913493754,
    "step": 19000
  },
  {
    "loss": 0.6365,
    "grad_norm": 3.9015376567840576,
    "learning_rate": 2.0303076454462382e-05,
    "epoch": 2.969844654279622,
    "step": 19500
  },
  {
    "eval_loss": 1.02084481716156,
    "eval_accuracy": 0.6679613129236158,
    "eval_runtime": 195.7131,
    "eval_samples_per_second": 134.186,
    "eval_steps_per_second": 8.39,
    "epoch": 3.0,
    "step": 19698
  },
  {
    "loss": 0.55,
    "grad_norm": 7.694070816040039,
    "learning_rate": 1.9541577825159914e-05,
    "epoch": 3.045994517209869,
    "step": 20000
  },
  {
    "loss": 0.4648,
    "grad_norm": 8.31737995147705,
    "learning_rate": 1.878007919585745e-05,
    "epoch": 3.122144380140116,
    "step": 20500
  },
  {
    "loss": 0.4635,
    "grad_norm": 10.343605041503906,
    "learning_rate": 1.801858056655498e-05,
    "epoch": 3.1982942430703627,
    "step": 21000
  },
  {
    "loss": 0.4686,
    "grad_norm": 9.456426620483398,
    "learning_rate": 1.7257081937252516e-05,
    "epoch": 3.274444106000609,
    "step": 21500
  },
  {
    "loss": 0.4624,
    "grad_norm": 6.779158115386963,
    "learning_rate": 1.6495583307950048e-05,
    "epoch": 3.350593968930856,
    "step": 22000
  },
  {
    "loss": 0.478,
    "grad_norm": 10.640886306762695,
    "learning_rate": 1.573408467864758e-05,
    "epoch": 3.4267438318611028,
    "step": 22500
  },
  {
    "loss": 0.455,
    "grad_norm": 13.643396377563477,
    "learning_rate": 1.497258604934511e-05,
    "epoch": 3.502893694791349,
    "step": 23000
  },
  {
    "loss": 0.4901,
    "grad_norm": 1.2828688621520996,
    "learning_rate": 1.4211087420042645e-05,
    "epoch": 3.579043557721596,
    "step": 23500
  },
  {
    "loss": 0.4799,
    "grad_norm": 8.561732292175293,
    "learning_rate": 1.3449588790740177e-05,
    "epoch": 3.655193420651843,
    "step": 24000
  },
  {
    "loss": 0.4747,
    "grad_norm": 13.487150192260742,
    "learning_rate": 1.2688090161437711e-05,
    "epoch": 3.7313432835820897,
    "step": 24500
  },
  {
    "loss": 0.4761,
    "grad_norm": 13.5962553024292,
    "learning_rate": 1.1926591532135243e-05,
    "epoch": 3.8074931465123365,
    "step": 25000
  },
  {
    "loss": 0.4827,
    "grad_norm": 6.152421474456787,
    "learning_rate": 1.1165092902832776e-05,
    "epoch": 3.883643009442583,
    "step": 25500
  },
  {
    "loss": 0.4877,
    "grad_norm": 7.548360824584961,
    "learning_rate": 1.0403594273530308e-05,
    "epoch": 3.9597928723728297,
    "step": 26000
  },
  {
    "eval_loss": 1.1832448244094849,
    "eval_accuracy": 0.665295864747544,
    "eval_runtime": 195.7495,
    "eval_samples_per_second": 134.161,
    "eval_steps_per_second": 8.388,
    "epoch": 4.0,
    "step": 26264
  },
  {
    "loss": 0.4015,
    "grad_norm": 4.52209997177124,
    "learning_rate": 9.642095644227842e-06,
    "epoch": 4.035942735303077,
    "step": 26500
  },
  {
    "loss": 0.342,
    "grad_norm": 12.746329307556152,
    "learning_rate": 8.880597014925374e-06,
    "epoch": 4.112092598233323,
    "step": 27000
  },
  {
    "loss": 0.3475,
    "grad_norm": 22.04045295715332,
    "learning_rate": 8.119098385622906e-06,
    "epoch": 4.18824246116357,
    "step": 27500
  },
  {
    "loss": 0.3522,
    "grad_norm": 9.219422340393066,
    "learning_rate": 7.357599756320439e-06,
    "epoch": 4.264392324093817,
    "step": 28000
  },
  {
    "loss": 0.3498,
    "grad_norm": 12.618233680725098,
    "learning_rate": 6.596101127017971e-06,
    "epoch": 4.340542187024063,
    "step": 28500
  },
  {
    "loss": 0.328,
    "grad_norm": 7.454331874847412,
    "learning_rate": 5.834602497715504e-06,
    "epoch": 4.41669204995431,
    "step": 29000
  },
  {
    "loss": 0.347,
    "grad_norm": 12.226814270019531,
    "learning_rate": 5.073103868413037e-06,
    "epoch": 4.492841912884557,
    "step": 29500
  },
  {
    "loss": 0.3512,
    "grad_norm": 20.690019607543945,
    "learning_rate": 4.31160523911057e-06,
    "epoch": 4.568991775814803,
    "step": 30000
  },
  {
    "loss": 0.3354,
    "grad_norm": 20.342496871948242,
    "learning_rate": 3.5501066098081023e-06,
    "epoch": 4.64514163874505,
    "step": 30500
  },
  {
    "loss": 0.3442,
    "grad_norm": 4.165218830108643,
    "learning_rate": 2.7886079805056355e-06,
    "epoch": 4.721291501675297,
    "step": 31000
  },
  {
    "loss": 0.3376,
    "grad_norm": 13.289848327636719,
    "learning_rate": 2.027109351203168e-06,
    "epoch": 4.797441364605544,
    "step": 31500
  },
  {
    "loss": 0.3515,
    "grad_norm": 21.118661880493164,
    "learning_rate": 1.2656107219007006e-06,
    "epoch": 4.87359122753579,
    "step": 32000
  },
  {
    "loss": 0.3299,
    "grad_norm": 24.991859436035156,
    "learning_rate": 5.041120925982333e-07,
    "epoch": 4.949741090466037,
    "step": 32500
  },
  {
    "eval_loss": 1.412554383277893,
    "eval_accuracy": 0.6592034117736654,
    "eval_runtime": 195.7961,
    "eval_samples_per_second": 134.129,
    "eval_steps_per_second": 8.386,
    "epoch": 5.0,
    "step": 32830
  },
  {
    "train_runtime": 12209.5135,
    "train_samples_per_second": 43.017,
    "train_steps_per_second": 2.689,
    "total_flos": 3.455120922207744e+16,
    "train_loss": 0.6779365023642896,
    "epoch": 5.0,
    "step": 32830
  }
]