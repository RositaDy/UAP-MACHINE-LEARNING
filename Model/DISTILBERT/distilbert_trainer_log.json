[
  {
    "loss": 1.6812,
    "grad_norm": 8.694079399108887,
    "learning_rate": 4.962001218397807e-05,
    "epoch": 0.07614986293024673,
    "step": 500
  },
  {
    "loss": 1.2948,
    "grad_norm": 7.8314313888549805,
    "learning_rate": 4.923926286932684e-05,
    "epoch": 0.15229972586049345,
    "step": 1000
  },
  {
    "loss": 1.2,
    "grad_norm": 8.816486358642578,
    "learning_rate": 4.8858513554675604e-05,
    "epoch": 0.22844958879074018,
    "step": 1500
  },
  {
    "loss": 1.1322,
    "grad_norm": 8.327239990234375,
    "learning_rate": 4.847776424002437e-05,
    "epoch": 0.3045994517209869,
    "step": 2000
  },
  {
    "loss": 1.0948,
    "grad_norm": 5.628223896026611,
    "learning_rate": 4.8097014925373136e-05,
    "epoch": 0.38074931465123363,
    "step": 2500
  },
  {
    "loss": 1.0694,
    "grad_norm": 8.235770225524902,
    "learning_rate": 4.77162656107219e-05,
    "epoch": 0.45689917758148035,
    "step": 3000
  },
  {
    "loss": 1.0463,
    "grad_norm": 7.258632659912109,
    "learning_rate": 4.733551629607067e-05,
    "epoch": 0.5330490405117271,
    "step": 3500
  },
  {
    "loss": 1.0362,
    "grad_norm": 7.638587474822998,
    "learning_rate": 4.6954766981419434e-05,
    "epoch": 0.6091989034419738,
    "step": 4000
  },
  {
    "loss": 1.0207,
    "grad_norm": 7.0239787101745605,
    "learning_rate": 4.65740176667682e-05,
    "epoch": 0.6853487663722205,
    "step": 4500
  },
  {
    "loss": 1.0068,
    "grad_norm": 4.3535284996032715,
    "learning_rate": 4.619326835211697e-05,
    "epoch": 0.7614986293024673,
    "step": 5000
  },
  {
    "loss": 1.0015,
    "grad_norm": 6.012902736663818,
    "learning_rate": 4.581251903746573e-05,
    "epoch": 0.837648492232714,
    "step": 5500
  },
  {
    "loss": 0.9671,
    "grad_norm": 7.092331409454346,
    "learning_rate": 4.54317697228145e-05,
    "epoch": 0.9137983551629607,
    "step": 6000
  },
  {
    "loss": 0.9842,
    "grad_norm": 5.589732646942139,
    "learning_rate": 4.505102040816327e-05,
    "epoch": 0.9899482180932074,
    "step": 6500
  },
  {
    "eval_loss": 0.9732301831245422,
    "eval_accuracy": 0.663963140659508,
    "eval_runtime": 34.7019,
    "eval_samples_per_second": 756.789,
    "eval_steps_per_second": 47.317,
    "epoch": 1.0,
    "step": 6566
  },
  {
    "loss": 0.8617,
    "grad_norm": 5.239025115966797,
    "learning_rate": 4.4670271093512036e-05,
    "epoch": 1.0660980810234542,
    "step": 7000
  },
  {
    "loss": 0.8578,
    "grad_norm": 6.040176868438721,
    "learning_rate": 4.4289521778860796e-05,
    "epoch": 1.1422479439537008,
    "step": 7500
  },
  {
    "loss": 0.8476,
    "grad_norm": 10.226637840270996,
    "learning_rate": 4.390877246420957e-05,
    "epoch": 1.2183978068839476,
    "step": 8000
  },
  {
    "loss": 0.8551,
    "grad_norm": 5.747185707092285,
    "learning_rate": 4.3528023149558334e-05,
    "epoch": 1.2945476698141944,
    "step": 8500
  },
  {
    "loss": 0.8623,
    "grad_norm": 6.782149314880371,
    "learning_rate": 4.31472738349071e-05,
    "epoch": 1.370697532744441,
    "step": 9000
  },
  {
    "loss": 0.8772,
    "grad_norm": 5.98338508605957,
    "learning_rate": 4.2766524520255866e-05,
    "epoch": 1.4468473956746877,
    "step": 9500
  },
  {
    "loss": 0.8633,
    "grad_norm": 8.166086196899414,
    "learning_rate": 4.238577520560463e-05,
    "epoch": 1.5229972586049345,
    "step": 10000
  },
  {
    "loss": 0.8579,
    "grad_norm": 5.535055160522461,
    "learning_rate": 4.20050258909534e-05,
    "epoch": 1.5991471215351813,
    "step": 10500
  },
  {
    "loss": 0.8564,
    "grad_norm": 4.789590835571289,
    "learning_rate": 4.1624276576302164e-05,
    "epoch": 1.675296984465428,
    "step": 11000
  },
  {
    "loss": 0.8452,
    "grad_norm": 6.13852596282959,
    "learning_rate": 4.124352726165093e-05,
    "epoch": 1.7514468473956746,
    "step": 11500
  },
  {
    "loss": 0.8623,
    "grad_norm": 8.31767749786377,
    "learning_rate": 4.0862777946999696e-05,
    "epoch": 1.8275967103259214,
    "step": 12000
  },
  {
    "loss": 0.8435,
    "grad_norm": 10.155193328857422,
    "learning_rate": 4.048202863234846e-05,
    "epoch": 1.9037465732561683,
    "step": 12500
  },
  {
    "loss": 0.8513,
    "grad_norm": 6.745918273925781,
    "learning_rate": 4.0101279317697235e-05,
    "epoch": 1.9798964361864149,
    "step": 13000
  },
  {
    "eval_loss": 0.932081401348114,
    "eval_accuracy": 0.676186124438352,
    "eval_runtime": 34.8255,
    "eval_samples_per_second": 754.103,
    "eval_steps_per_second": 47.149,
    "epoch": 2.0,
    "step": 13132
  },
  {
    "loss": 0.7292,
    "grad_norm": 12.451410293579102,
    "learning_rate": 3.9720530003045994e-05,
    "epoch": 2.0560462991166615,
    "step": 13500
  },
  {
    "loss": 0.6762,
    "grad_norm": 8.836342811584473,
    "learning_rate": 3.933978068839476e-05,
    "epoch": 2.1321961620469083,
    "step": 14000
  },
  {
    "loss": 0.6945,
    "grad_norm": 5.901215076446533,
    "learning_rate": 3.8959031373743526e-05,
    "epoch": 2.208346024977155,
    "step": 14500
  },
  {
    "loss": 0.7021,
    "grad_norm": 3.4493613243103027,
    "learning_rate": 3.85782820590923e-05,
    "epoch": 2.2844958879074015,
    "step": 15000
  },
  {
    "loss": 0.6888,
    "grad_norm": 7.677029132843018,
    "learning_rate": 3.8197532744441064e-05,
    "epoch": 2.3606457508376484,
    "step": 15500
  },
  {
    "loss": 0.7053,
    "grad_norm": 7.33355188369751,
    "learning_rate": 3.7816783429789824e-05,
    "epoch": 2.436795613767895,
    "step": 16000
  },
  {
    "loss": 0.7176,
    "grad_norm": 7.336180686950684,
    "learning_rate": 3.7436034115138596e-05,
    "epoch": 2.512945476698142,
    "step": 16500
  },
  {
    "loss": 0.6939,
    "grad_norm": 9.037579536437988,
    "learning_rate": 3.705528480048736e-05,
    "epoch": 2.589095339628389,
    "step": 17000
  },
  {
    "loss": 0.7268,
    "grad_norm": 8.591873168945312,
    "learning_rate": 3.667453548583613e-05,
    "epoch": 2.6652452025586353,
    "step": 17500
  },
  {
    "loss": 0.7102,
    "grad_norm": 6.299983978271484,
    "learning_rate": 3.6293786171184894e-05,
    "epoch": 2.741395065488882,
    "step": 18000
  },
  {
    "loss": 0.7259,
    "grad_norm": 8.23482894897461,
    "learning_rate": 3.591303685653366e-05,
    "epoch": 2.817544928419129,
    "step": 18500
  },
  {
    "loss": 0.7071,
    "grad_norm": 8.612056732177734,
    "learning_rate": 3.5532287541882426e-05,
    "epoch": 2.8936947913493754,
    "step": 19000
  },
  {
    "loss": 0.7151,
    "grad_norm": 3.1611602306365967,
    "learning_rate": 3.515153822723119e-05,
    "epoch": 2.969844654279622,
    "step": 19500
  },
  {
    "eval_loss": 0.9963477849960327,
    "eval_accuracy": 0.6679232350925292,
    "eval_runtime": 34.6896,
    "eval_samples_per_second": 757.056,
    "eval_steps_per_second": 47.334,
    "epoch": 3.0,
    "step": 19698
  },
  {
    "loss": 0.6138,
    "grad_norm": 5.404551029205322,
    "learning_rate": 3.477078891257996e-05,
    "epoch": 3.045994517209869,
    "step": 20000
  },
  {
    "loss": 0.5364,
    "grad_norm": 8.944665908813477,
    "learning_rate": 3.4390039597928724e-05,
    "epoch": 3.122144380140116,
    "step": 20500
  },
  {
    "loss": 0.5423,
    "grad_norm": 8.802319526672363,
    "learning_rate": 3.400929028327749e-05,
    "epoch": 3.1982942430703627,
    "step": 21000
  },
  {
    "loss": 0.5291,
    "grad_norm": 6.464923858642578,
    "learning_rate": 3.362854096862626e-05,
    "epoch": 3.274444106000609,
    "step": 21500
  },
  {
    "loss": 0.5454,
    "grad_norm": 15.736576080322266,
    "learning_rate": 3.324779165397502e-05,
    "epoch": 3.350593968930856,
    "step": 22000
  },
  {
    "loss": 0.5548,
    "grad_norm": 10.47746467590332,
    "learning_rate": 3.286704233932379e-05,
    "epoch": 3.4267438318611028,
    "step": 22500
  },
  {
    "loss": 0.5466,
    "grad_norm": 13.298711776733398,
    "learning_rate": 3.248629302467256e-05,
    "epoch": 3.502893694791349,
    "step": 23000
  },
  {
    "loss": 0.5715,
    "grad_norm": 8.484209060668945,
    "learning_rate": 3.2105543710021326e-05,
    "epoch": 3.579043557721596,
    "step": 23500
  },
  {
    "loss": 0.5704,
    "grad_norm": 5.90254020690918,
    "learning_rate": 3.1724794395370086e-05,
    "epoch": 3.655193420651843,
    "step": 24000
  },
  {
    "loss": 0.5659,
    "grad_norm": 6.86499547958374,
    "learning_rate": 3.134404508071885e-05,
    "epoch": 3.7313432835820897,
    "step": 24500
  },
  {
    "loss": 0.5812,
    "grad_norm": 12.753702163696289,
    "learning_rate": 3.0963295766067624e-05,
    "epoch": 3.8074931465123365,
    "step": 25000
  },
  {
    "loss": 0.59,
    "grad_norm": 9.5840425491333,
    "learning_rate": 3.058254645141639e-05,
    "epoch": 3.883643009442583,
    "step": 25500
  },
  {
    "loss": 0.5804,
    "grad_norm": 7.283088684082031,
    "learning_rate": 3.0201797136765153e-05,
    "epoch": 3.9597928723728297,
    "step": 26000
  },
  {
    "eval_loss": 1.1328496932983398,
    "eval_accuracy": 0.6657527987205849,
    "eval_runtime": 34.6247,
    "eval_samples_per_second": 758.477,
    "eval_steps_per_second": 47.423,
    "epoch": 4.0,
    "step": 26264
  },
  {
    "train_runtime": 1890.1206,
    "train_samples_per_second": 555.753,
    "train_steps_per_second": 34.739,
    "total_flos": 1.3917635102846976e+16,
    "train_loss": 0.8090129925498067,
    "epoch": 4.0,
    "step": 26264
  }
]